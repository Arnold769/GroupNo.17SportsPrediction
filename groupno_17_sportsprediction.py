# -*- coding: utf-8 -*-
"""GroupNo.17_SportsPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BjbTVKW5NI0x-WxlBumaXvYJ4e41wc_B
"""

#importing modules
import pandas as pd
import os
import sklearn
import numpy as np
import pandas as pd
import numpy as np, pandas as pd
import matplotlib.pyplot as plt
from sklearn import tree, metrics
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
from google.colab import drive
import joblib

drive.mount('/content/drive')

"""DATA PREPOROCESSING"""

#loading the dataset for preproccesing and feature engineering
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/players_21.csv')
df.info()

#finding the correlation between each feature and the overall rating of the player
#finding the correlation between each physical attribute and the overall rating of the player is our focus, rather than using extrinsic features such as wages and club name
selected_features = ['overall', 'potential', 'age', 'height_cm', 'weight_kg', 'pace', 'shooting', 'passing',
                     'dribbling', 'defending', 'physic', 'attacking_crossing', 'attacking_finishing',
                     'attacking_heading_accuracy', 'attacking_short_passing', 'attacking_volleys',
                     'skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing',
                     'skill_ball_control', 'movement_acceleration', 'movement_sprint_speed', 'movement_agility',
                     'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping', 'power_stamina',
                     'power_strength', 'power_long_shots', 'mentality_aggression', 'mentality_interceptions',
                     'mentality_positioning', 'mentality_vision', 'mentality_penalties', 'mentality_composure',
                     'defending_marking_awareness', 'defending_standing_tackle', 'defending_sliding_tackle',
                     'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning',
                     'goalkeeping_reflexes', 'goalkeeping_speed']
correlation_matrix = df[selected_features].corr()
#sorts the features with the heighest correlation to the overall in ascending order
correlation_matrix['overall'].sort_values(ascending=False)

#selecting the best correlated features
selected_columns = ['skill_long_passing', 'skill_ball_control', 'skill_curve', 'skill_fk_accuracy', 'skill_dribbling',
                    'goalkeeping_handling', 'attacking_crossing', 'movement_reactions', 'age',
                    'mentality_aggression', 'mentality_vision', 'mentality_interceptions', 'goalkeeping_kicking',
                    'goalkeeping_speed', 'shooting', 'dribbling', 'power_shot_power','power_long_shots', 'defending', 'goalkeeping_reflexes',
                    'potential', 'mentality_composure', 'mentality_positioning', 'mentality_penalties', 'passing',
                    'attacking_short_passing', 'physic', 'overall', 'goalkeeping_positioning', 'goalkeeping_diving',
                    'attacking_volleys', 'attacking_finishing']

#loading the dataset with the best correlated features
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/players_21.csv', usecols=selected_columns)
df.info()

df.head()

# replacing nan values with 0
df.fillna(0, inplace=True)
# combine instances with overall ratings 92 and 93 into a single class '92'
df['overall'] = df['overall'].apply(lambda x: 92 if x in [92, 93] else x)

"""FEATURE ENGINEERING"""

# we combined multiply features with similar attributes to form one feature.
# this helped us decrease the mean absolute error of our model when testing

shooting_attributes = ['shooting', 'power_shot_power', 'power_long_shots', 'attacking_volleys','attacking_finishing']

df['shooting_skills'] = df[shooting_attributes].mean(axis=1)

df.drop(columns=shooting_attributes, inplace=True)

df.info()

# we combined multiply features with similar attributes to form one feature.
# this helped us decrease the mean absolute error of our model when testing
mentality_attributes = ['mentality_aggression', 'mentality_interceptions', 'mentality_positioning',
                        'mentality_vision', 'mentality_penalties', 'mentality_composure']
imputer = SimpleImputer(strategy='mean')
df[mentality_attributes] = imputer.fit_transform(df[mentality_attributes])

df['mentality'] = df[mentality_attributes].mean(axis=1)

df.drop(columns=mentality_attributes, inplace=True)

df.info()

# we combined multiply features with similar attributes to form one feature.
# this helped us decrease the mean absolute error of our model when testing

skill_attributes = ['skill_long_passing', 'skill_ball_control', 'skill_curve', 'skill_fk_accuracy', 'skill_dribbling']

df['technical_skills'] = df[skill_attributes].mean(axis=1)

df.drop(columns=skill_attributes, inplace=True)

df.info()

# transform float values to int type for easier manipulation
df= df.astype(int)
# we combined multiply features with similar attributes to form one feature.
# this helped us decrease the mean absolute error of our model when testing

goalkeeping_attributes = ['goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking',
                          'goalkeeping_positioning', 'goalkeeping_reflexes', 'goalkeeping_speed']

imputer = SimpleImputer(strategy='mean')
df[goalkeeping_attributes] = imputer.fit_transform(df[goalkeeping_attributes])

df['goalkeeping_ability'] = df[goalkeeping_attributes].mean(axis=1)

df.drop(columns=goalkeeping_attributes, inplace=True)

df.info()

df.info()

df= df.astype(int)

df.info()

"""TRAINING"""

# extracting the target variable 'overall' (player's overall rating) and the feature variables from the DataFrame.
y = df['overall']  # target variable representing player's overall rating (Y values)
X = df.drop('overall', axis=1)  # feature variables excluding the 'overall' column (X values)

# importing the StandardScaler module from sklearn.preprocessing package.
from sklearn.preprocessing import StandardScaler

# initializing the StandardScaler object.
sc = StandardScaler()

# applying the StandardScaler to transform the feature variables (X) into a standardized form.
scaled = sc.fit_transform(X)

#creating a dataframe for feature variables
X=pd.DataFrame(scaled, columns=X.columns)

y.head()

X.head()
X.info()

y.value_counts()

# splitting the dataset into training and testing sets using train_test_split function.
# Xtrain: features for training, Xtest: features for testing, Ytrain: target values for training, Ytest: target values for testing.
Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)

# displaying the shape of the training feature set (Xtrain).
Xtrain.shape

"""**TRAINING**

USING RANDOM FOREST REGRESSOR
"""

# importing the RandomForestRegressor module from the sklearn.ensemble package.
from sklearn.ensemble import RandomForestRegressor

# initializing the RandomForestRegressor model
rf=RandomForestRegressor()

# training the model using the training data (Xtrain and Ytrain)
rf.fit(Xtrain, Ytrain)

# making predictions on the test data (Xtest) using the trained model.
y_pred=rf.predict(Xtest)
y_pred

# calculating the mean absolute error between the predicted values (y_pred) and the actual values (Ytest).
mean_absolute_error(y_pred,Ytest)

"""USING XGB_REGRESSOR"""

# importing the XGBRegressor module from the xgboost package.
from xgboost import XGBRegressor

# initializing the XGBRegressor model.
xgb_model = XGBRegressor()

# training the XGBRegressor model using the training data (Xtrain and Ytrain).
xgb_model.fit(Xtrain, Ytrain)

# making predictions on the test data (Xtest) using the trained XGBRegressor model.
y_pred_xgb = xgb_model.predict(Xtest)

# calculating the mean absolute error between the XGBRegressor predicted values (y_pred_xgb) and the actual values (Ytest).
mae_xgb = mean_absolute_error(y_pred_xgb, Ytest)
mae_xgb

"""USING GRADIENT_BOOSTING_REGRESSOR"""

# importing the GradientBoostingRegressor module from the sklearn.ensemble package.
from sklearn.ensemble import GradientBoostingRegressor

# initializing the GradientBoostingRegressor model.
gb_model = GradientBoostingRegressor()

# training the GradientBoostingRegressor model using the training data (Xtrain and Ytrain).
gb_model.fit(Xtrain, Ytrain)

# making predictions on the test data (Xtest) using the trained GradientBoostingRegressor model.
y_pred_gb = gb_model.predict(Xtest)

# calculating the mean absolute error between the GradientBoostingRegressor predicted values (y_pred_gb) and the actual values (Ytest).
mae_gb = mean_absolute_error(y_pred_gb, Ytest)
mae_gb

"""CROSS-VALIDATION USING GRID SEARCH"""

from sklearn.model_selection import GridSearchCV

# these are the hyperparameters for Random Forest
rf_params = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10]
}

# these are the hyperparameters for XGBoost
xgb_params = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.1, 0.01, 0.001]
}

# performed a grid search with cross-validation to find the best RandomForestRegressor model using negative mean absolute error as the scoring metric.
grid_rf = GridSearchCV(estimator=RandomForestRegressor(),
                       param_grid=rf_params,
                       scoring='neg_mean_absolute_error',
                       cv=5)
grid_rf.fit(Xtrain, Ytrain)
best_rf = grid_rf.best_estimator_

# perform grid search with cross-validation to find the best XGBRegressor model using negative mean absolute error as the scoring metric.
grid_xgb = GridSearchCV(estimator=XGBRegressor(),
                        param_grid=xgb_params,
                        scoring='neg_mean_absolute_error',
                        cv=5)
grid_xgb.fit(Xtrain, Ytrain)
best_xgb = grid_xgb.best_estimator_

y_pred_best_rf = best_rf.predict(Xtest)
mae_best_rf = mean_absolute_error(y_pred_best_rf, Ytest)
print("Mean Absolute Error for Best Random Forest Model: ", mae_best_rf)

y_pred_best_xgb = best_xgb.predict(Xtest)
mae_best_xgb = mean_absolute_error(y_pred_best_xgb, Ytest)
print("Mean Absolute Error for Best XGBoost Model: ", mae_best_xgb)

"""ENSEMBLE MODEL USING ALL TWO MODELS (RF & XGB) ABOVE

"""

#for the ensemble model we used only the RF and XGB because the gradient boosting regressor increase the mean absolute error and hence the ensemble model needed optimization
from sklearn.ensemble import VotingRegressor

ensemble_model = VotingRegressor(estimators=[('rf', rf), ('xgb', xgb_model)])

# Training the ensemble model
ensemble_model.fit(Xtrain, Ytrain)

# Making predictions using the ensemble model
ensemble_predictions = ensemble_model.predict(Xtest)

"""EVALUATION"""

# Calculating mean absolute error for the ensemble predictions
mae_ensemble = mean_absolute_error(ensemble_predictions, Ytest)
ensemble_predictions
Xtest
Ytest

print("Mean Absolute Error for Random Forest: ", mean_absolute_error(y_pred, Ytest))
print("Mean Absolute Error for XGBoost: ", mae_xgb)
print("Mean Absolute Error for Ensemble Model: ", mae_ensemble)

"""CONFIDENCE SCORE"""

# Assuming you have an array of predictions from K-fold cross-validation named 'predictions'
mean_prediction = np.mean(ensemble_predictions)
std_deviation = np.std(ensemble_predictions)

from scipy.stats import norm

# specified the confidence level
confidence_level = 0.95

# calculate the margin of error
z_score = norm.ppf((1 + confidence_level) / 2)  # Z-score for the given confidence level
margin_of_error = z_score * (std_deviation / np.sqrt(len(ensemble_predictions)))

# Calculate lower and upper bounds of the confidence interval
lower_bound = mean_prediction - margin_of_error
upper_bound = mean_prediction + margin_of_error
confidence_percentage = (1 - 2 * (1 - confidence_level)) * 100

print("Lower bound:", lower_bound)
print("Upper bound:", upper_bound)
print("Margin of error:", margin_of_error)
print("Confidence Percentage:", confidence_percentage)

"""TRAINING MODEL USING NEW DATASET (PLAYERS_22)"""

# Load the new dataset
new_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/players_22.csv', usecols=selected_columns)

"""**DATA PREPOCESSING**"""

new_df.fillna(0, inplace=True)
new_df['overall'] = new_df['overall'].apply(lambda x: 92 if x in [92, 93] else x)

"""**FEATURE ENGINEERING**"""

skill_attributes = ['skill_long_passing', 'skill_ball_control', 'skill_curve', 'skill_fk_accuracy', 'skill_dribbling']

new_df['technical_skills'] = new_df[skill_attributes].mean(axis=1)

new_df.drop(columns=skill_attributes, inplace=True)

new_df.info()

shooting_attributes = ['shooting', 'power_shot_power', 'power_long_shots', 'attacking_volleys','attacking_finishing']

new_df['shooting_skills'] = new_df[shooting_attributes].mean(axis=1)

new_df.drop(columns=shooting_attributes, inplace=True)

new_df.info()

mentality_attributes = ['mentality_aggression', 'mentality_interceptions', 'mentality_positioning',
                        'mentality_vision', 'mentality_penalties', 'mentality_composure']
imputer = SimpleImputer(strategy='mean')
new_df[mentality_attributes] = imputer.fit_transform(new_df[mentality_attributes])

new_df['mentality'] = new_df[mentality_attributes].mean(axis=1)

new_df.drop(columns=mentality_attributes, inplace=True)

new_df.info()

goalkeeping_attributes = ['goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking',
                          'goalkeeping_positioning', 'goalkeeping_reflexes', 'goalkeeping_speed']

imputer = SimpleImputer(strategy='mean')
new_df[goalkeeping_attributes] = imputer.fit_transform(new_df[goalkeeping_attributes])

new_df['goalkeeping_ability'] = new_df[goalkeeping_attributes].mean(axis=1)

new_df.drop(columns=goalkeeping_attributes, inplace=True)

new_df.info()

"""**TRAINING AND EVALUATION**"""

y_new = new_df['overall']
X_new = new_df.drop('overall', axis=1)
X_new

scaled_X_new = sc.fit_transform(X_new)
X_new = pd.DataFrame(scaled_X_new, columns=X_new.columns)

X_new_train,X_new_test,Y_new_train,Y_new_test=train_test_split(X_new,y_new,test_size=0.1,random_state=42,stratify = y_new)

rf.fit(X_new_train, Y_new_train)
y_pred_rf = rf.predict(X_new_test)

mean_absolute_error(y_pred_rf,Y_new_test)

xgb_model.fit(X_new_train, Y_new_train)
y_pred_xgb = xgb_model.predict(X_new_test)
mae_xgb_new = mean_absolute_error(y_pred_xgb, Y_new_test)
mae_xgb_new

"""**Hyperparameter Tuning for Random Forest Regression**"""

from sklearn.model_selection import GridSearchCV

# Define the hyperparameters and their respective values to search through
param_grid = {
    'n_estimators': [50, 100, 150],  # Number of trees in the forest
    'max_depth': [None, 10, 20],  # Maximum depth of the tree
    'min_samples_split': [2, 5, 10],  # Minimum samples required to split an internal node
    'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required to be at a leaf node
}

# initialize Grid Search with 5-fold cross-validation
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# perform Grid Search on the training data
grid_search.fit(X_new_train, Y_new_train)

# Get the best hyperparameters found by Grid Search
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# initialize a new Random Forest Regressor with the best hyperparameters
best_rf = RandomForestRegressor(**best_params)

# train the model with the best hyperparameters
best_rf.fit(X_new_train, Y_new_train)

# make predictions using the tuned model
y_pred_rf_tuned = best_rf.predict(X_new_test)

# Calculate mean absolute error for the tuned model
mae_rf_tuned = mean_absolute_error(y_pred_rf_tuned, Y_new_test)
print("Mean Absolute Error for Tuned Random Forest: ", mae_rf_tuned)

"""**Hyperparameter Tuning for XGBoost Regression**"""

from sklearn.model_selection import GridSearchCV

# define the hyperparameters and their respective values to search through
param_grid = {
    'n_estimators': [50, 100, 150],  # Number of boosting rounds
    'max_depth': [3, 6, 9],  # Maximum depth of the tree
    'learning_rate': [0.01, 0.1, 0.2],  # Step size shrinkage used to prevent overfitting
    'subsample': [0.8, 1.0],  # Fraction of samples used for fitting the trees
    'min_child_weight': [1, 5, 10]  # Minimum sum of instance weight (hessian) needed in a child
}

# initialize Grid Search with 5-fold cross-validation
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# perform Grid Search on the training data
grid_search.fit(X_new_train, Y_new_train)

# get the best hyperparameters found by Grid Search
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# initialize a new XGBoost Regressor with the best hyperparameters
best_xgb = XGBRegressor(**best_params)

# train the model with the best hyperparameters
best_xgb.fit(X_new_train, Y_new_train)

# make predictions using the tuned model
y_pred_xgb_tuned = best_xgb.predict(X_new_test)

# calculate mean absolute error for the tuned model
mae_xgb_tuned = mean_absolute_error(y_pred_xgb_tuned, Y_new_test)
print("Mean Absolute Error for Tuned XGBoost: ", mae_xgb_tuned)

"""**TESTING USING THE ENSEMBLE MODEL**"""

from sklearn.ensemble import VotingRegressor

ensemble_model = VotingRegressor(estimators=[('rf', rf), ('xgb', xgb_model)])

ensemble_model.fit(Xtrain, Ytrain)

ensemble_predictions = ensemble_model.predict(Xtest)
print(ensemble_predictions)
print(Xtest)
print(Ytest)

mae_ensemble_new = mean_absolute_error(ensemble_predictions, Ytest)

mae_ensemble_new

# saving the scaler object using joblib for later use in ensemble models
joblib.dump(sc, '/content/drive/My Drive/Colab Notebooks/scaler_ensemble.pkl')

# save the ensemble model using pickle for future use
# pickle the ensemble model and save it to the specified file path
import pickle
filename = '/content/drive/My Drive/Colab Notebooks/sports_prediction_ensemble_model.pkl'
pickle.dump(ensemble_model, open(filename, 'wb'))
loaded_model = pickle.load(open(filename, 'rb'))